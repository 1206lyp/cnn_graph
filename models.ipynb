{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NFEATURES = 28**2\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's common API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class base_model(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.regularizers = 0\n",
    "    \n",
    "    def loss(self, logits, labels, regularization):\n",
    "        labels = tf.to_int64(labels)\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels, name='xentropy')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "        loss += regularization * self.regularizers\n",
    "        return loss\n",
    "    \n",
    "    def training(self, loss, learning_rate):\n",
    "        tf.scalar_summary(loss.op.name, loss)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        #optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return train_op\n",
    "    \n",
    "    def evaluation(self, logits, labels):\n",
    "        correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "        return tf.reduce_sum(tf.cast(correct, tf.int32))\n",
    "    \n",
    "    # Helpers\n",
    "    \n",
    "    def _weight_variable(self, shape, regularization=True):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        var = tf.Variable(initial, name='weights')\n",
    "        if regularization:\n",
    "            self.regularizers += tf.nn.l2_loss(var)\n",
    "        return var\n",
    "\n",
    "    def _bias_variable(self, shape, regularization=True):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        var = tf.Variable(initial, name='bias')\n",
    "        if regularization:\n",
    "            self.regularizers += tf.nn.l2_loss(var)\n",
    "        return var\n",
    "\n",
    "    def _conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fc1(base_model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def inference(self, x):\n",
    "        W = self._weight_variable([NFEATURES, NCLASSES])\n",
    "        b = self._bias_variable([NCLASSES])\n",
    "        y = tf.matmul(x, W) + b\n",
    "        return y\n",
    "\n",
    "class fc2(base_model):\n",
    "    def __init__(self, nhiddens):\n",
    "        super().__init__()\n",
    "        self.nhiddens = nhiddens\n",
    "    def inference(self, x):\n",
    "        with tf.name_scope('fc1'):\n",
    "            W = self._weight_variable([NFEATURES, self.nhiddens])\n",
    "            b = self._bias_variable([self.nhiddens])\n",
    "            y = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        with tf.name_scope('fc2'):\n",
    "            W = self._weight_variable([self.nhiddens, NCLASSES])\n",
    "            b = self._bias_variable([NCLASSES])\n",
    "            y = tf.matmul(y, W) + b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class cnn2(base_model):\n",
    "    \"\"\"Simple convolutional model.\"\"\"\n",
    "    def __init__(self, K, F):\n",
    "        super().__init__()\n",
    "        self.K = K  # Patch size\n",
    "        self.F = F  # Number of features\n",
    "    def inference(self, x):\n",
    "        with tf.name_scope('conv1'):\n",
    "            W = self._weight_variable([self.K, self.K, 1, self.F])\n",
    "            b = self._bias_variable([self.F])\n",
    "#            b = self._bias_variable([1, 28, 28, self.F])\n",
    "            x_2d = tf.reshape(x, [-1,28,28,1])\n",
    "            y_2d = self._conv2d(x_2d, W) + b\n",
    "            y_2d = tf.nn.relu(y_2d)\n",
    "        with tf.name_scope('fc1'):\n",
    "            y = tf.reshape(y_2d, [-1, NFEATURES*self.F])\n",
    "            W = self._weight_variable([NFEATURES*self.F, NCLASSES])\n",
    "            b = self._bias_variable([NCLASSES])\n",
    "            y = tf.matmul(y, W) + b\n",
    "        return y\n",
    "\n",
    "class fcnn2(base_model):\n",
    "    \"\"\"CNN using the FFT.\"\"\"\n",
    "    def __init__(self, F):\n",
    "        super().__init__()\n",
    "        self.F = F  # Number of features\n",
    "    def inference(self, x):\n",
    "        with tf.name_scope('conv1'):\n",
    "            # Transform to Fourier domain\n",
    "            x_2d = tf.reshape(x, [-1, 28, 28])\n",
    "            x_2d = tf.complex(x_2d, 0)\n",
    "            xf_2d = tf.batch_fft2d(x_2d)\n",
    "            xf = tf.reshape(xf_2d, [-1, NFEATURES])\n",
    "            xf = tf.expand_dims(xf, 1)  # NSAMPLES x 1 x NFEATURES\n",
    "            xf = tf.transpose(xf)  # NFEATURES x 1 x NSAMPLES\n",
    "            # Filter\n",
    "            Wreal = self._weight_variable([int(NFEATURES/2), self.F, 1])\n",
    "            Wimg = self._weight_variable([int(NFEATURES/2), self.F, 1])\n",
    "            W = tf.complex(Wreal, Wimg)\n",
    "            xf = xf[:int(NFEATURES/2), :, :]\n",
    "            yf = tf.batch_matmul(W, xf)  # for each feature\n",
    "            yf = tf.concat(0, [yf, tf.conj(yf)])\n",
    "            yf = tf.transpose(yf)  # NSAMPLES x NFILTERS x NFEATURES\n",
    "            yf_2d = tf.reshape(yf, [-1, 28, 28])\n",
    "            # Transform back to spatial domain\n",
    "            y_2d = tf.batch_ifft2d(yf_2d)\n",
    "            y_2d = tf.real(y_2d)\n",
    "            y = tf.reshape(y_2d, [-1, self.F, NFEATURES])\n",
    "            # Bias and non-linearity\n",
    "            b = self._bias_variable([1, self.F, 1])\n",
    "#            b = self._bias_variable([1, self.F, NFEATURES])\n",
    "            y += b  # NSAMPLES x NFILTERS x NFEATURES\n",
    "            y = tf.nn.relu(y)\n",
    "        with tf.name_scope('fc1'):\n",
    "            W = self._weight_variable([self.F*NFEATURES, NCLASSES])\n",
    "            b = self._bias_variable([NCLASSES])\n",
    "            y = tf.reshape(y, [-1, self.F*NFEATURES])\n",
    "            y = tf.matmul(y, W) + b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class fgcnn2(base_model):\n",
    "    \"\"\"Graph CNN with full weights, i.e. patch has the same size as input.\"\"\"\n",
    "    def __init__(self, U, F):\n",
    "        super().__init__()\n",
    "        self.U = U  # Graph Fourier basis, NFEATURES x NFEATURES\n",
    "        self.F = F  # Number of features\n",
    "    def inference(self, x):\n",
    "        # x: NSAMPLES x NFEATURES\n",
    "        with tf.name_scope('gconv1'):\n",
    "            # Transform to Fourier domain\n",
    "            U = tf.constant(self.U, dtype=tf.float32)\n",
    "            xf = tf.matmul(x, U)\n",
    "            xf = tf.expand_dims(xf, 1)  # NSAMPLES x 1 x NFEATURES\n",
    "            xf = tf.transpose(xf)  # NFEATURES x 1 x NSAMPLES\n",
    "            # Filter\n",
    "            W = self._weight_variable([NFEATURES, self.F, 1])\n",
    "            yf = tf.batch_matmul(W, xf)  # for each feature\n",
    "            yf = tf.transpose(yf)  # NSAMPLES x NFILTERS x NFEATURES\n",
    "            yf = tf.reshape(yf, [-1, NFEATURES])\n",
    "            # Transform back to graph domain\n",
    "            Ut = tf.transpose(U)\n",
    "            y = tf.matmul(yf, Ut)\n",
    "            y = tf.reshape(yf, [-1, self.F, NFEATURES])\n",
    "            # Bias and non-linearity\n",
    "            b = self._bias_variable([1, self.F, 1])\n",
    "#            b = self._bias_variable([1, self.F, NFEATURES])\n",
    "            y += b  # NSAMPLES x NFILTERS x NFEATURES\n",
    "            y = tf.nn.relu(y)\n",
    "        with tf.name_scope('fc1'):\n",
    "            W = self._weight_variable([self.F*NFEATURES, NCLASSES])\n",
    "            b = self._bias_variable([NCLASSES])\n",
    "            y = tf.reshape(y, [-1, self.F*NFEATURES])\n",
    "            y = tf.matmul(y, W) + b\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
