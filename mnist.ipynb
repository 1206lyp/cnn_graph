{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#import models\n",
    "%run -n models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "# 0.1 for cnn2, 1.0 for fgcnn2\n",
    "flags.DEFINE_float('learning_rate', 1.0, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')\n",
    "flags.DEFINE_float('regularization', 0, 'L2 regularizations of weights and biases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data_mnist\", one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid(m):\n",
    "    M = m**2\n",
    "    x = np.linspace(0,1,m)\n",
    "    y = np.linspace(0,1,m)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = np.empty((M,2))\n",
    "    z[:,0] = xx.reshape(M)\n",
    "    z[:,1] = yy.reshape(M)\n",
    "    return z\n",
    "    \n",
    "def graph(z, k=4):\n",
    "    M = z.shape[0]\n",
    "\n",
    "    # Compute pairwise distances.\n",
    "    d = scipy.spatial.distance.pdist(z, 'euclidean')\n",
    "    d = scipy.spatial.distance.squareform(d)\n",
    "\n",
    "    # k-NN graph.\n",
    "    idx = np.argsort(d)[:,1:k+1]\n",
    "    d.sort()\n",
    "    d = d[:,1:k+1]\n",
    "\n",
    "    # Weights.\n",
    "    sigma2 = np.mean(d[:,-1])**2\n",
    "    d = np.exp(- d**2 / sigma2)\n",
    "\n",
    "    # Weight matrix.\n",
    "    I = np.arange(0, M).repeat(k)\n",
    "    J = idx.reshape(M*k)\n",
    "    V = d.reshape(M*k)\n",
    "    W = scipy.sparse.coo_matrix((V, (I, J)), shape=(M, M))\n",
    "    \n",
    "    # No self-connections.\n",
    "    W.setdiag(0)\n",
    "\n",
    "    # Non-directed graph.\n",
    "    bigger = W.T > W\n",
    "    W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "    del bigger\n",
    "    assert np.abs(W - W.T).mean() < 1e-10\n",
    "\n",
    "    # CSR sparse matrix format for efficient multiplications.\n",
    "    W = W.tocsr()\n",
    "    W.eliminate_zeros()\n",
    "    \n",
    "    print(\"{} > {} edges\".format(W.nnz, M*k))\n",
    "    return W\n",
    "\n",
    "W = graph(grid(28), k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplacian(W, normalized=True):\n",
    "    \"\"\"Return the Laplacian of the weigth matrix.\"\"\"\n",
    "    \n",
    "    # Degree matrix.\n",
    "    d = W.sum(axis=0)\n",
    "\n",
    "    # Laplacian matrix.\n",
    "    if not normalized:\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        L = D - W\n",
    "    else:\n",
    "        d = 1 / np.sqrt(d)\n",
    "        D = scipy.sparse.diags(d.A.squeeze(), 0)\n",
    "        I = scipy.sparse.identity(d.size, dtype=D.dtype)\n",
    "        L = I - D * W * D\n",
    "    \n",
    "    # Upper-bound on the spectrum.\n",
    "    if normalized:\n",
    "        lmax = 2\n",
    "    else:\n",
    "        lmax = scipy.sparse.linalg.eigsh(L, k=1, which='LM', return_eigenvectors=False)[0]\n",
    "    \n",
    "    assert np.abs(L - L.T).mean() < 1e-10\n",
    "    return L, lmax\n",
    "\n",
    "L, lmax = laplacian(W, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fourier(L):\n",
    "\n",
    "    def sort(lamb, U):\n",
    "        idx = lamb.argsort()\n",
    "        return lamb[idx], U[:,idx]\n",
    "\n",
    "    t_start = time.process_time()\n",
    "    lamb, U = np.linalg.eig(L.toarray())\n",
    "    lamb, U = sort(lamb, U)\n",
    "    print('Execution time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "    return lamb, U\n",
    "\n",
    "lamb, U = fourier(L)\n",
    "print('Spectrum in [{:1.2e}, {:1.2e}]'.format(lamb[0], lamb[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = tf.placeholder(tf.float32, (FLAGS.batch_size, 784))\n",
    "#y = tf.placeholder(tf.int32, (FLAGS.batch_size))\n",
    "x = tf.placeholder(tf.float32, (None, 784))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "model = fc1()\n",
    "model = fc2(nhiddens=100)\n",
    "model = cnn2(K=5, F=10)  # K=28 is equivalent to filtering with fgcnn.\n",
    "model = fgcnn2(U, F=10)\n",
    "\n",
    "# Construct computational graph\n",
    "logits = model.inference(x)\n",
    "loss = model.loss(logits, y, FLAGS.regularization)\n",
    "train_op = model.training(loss, FLAGS.learning_rate)\n",
    "eval_correct = model.evaluation(logits, y)\n",
    "\n",
    "# Train\n",
    "t_start = time.process_time()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(int(1e4)):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)\n",
    "    sess.run(train_op, feed_dict={x: batch_xs, y: batch_ys})\n",
    "print('Training time: {:.2f}s'.format(time.process_time() - t_start))\n",
    "\n",
    "# Evaluate\n",
    "ncorrects = sess.run(eval_correct, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "precision = ncorrects / mnist.test.num_examples\n",
    "print('Precision: {:.2f}% ({:d} / {:d})'.format(precision*100, ncorrects, mnist.test.num_examples))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
